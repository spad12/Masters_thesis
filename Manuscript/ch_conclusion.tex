\chapter{Conclusion}

\section{Review}
Towards the end of chapter \ref{ch:introduction} we stated the primary goals of this project. We set out to develop a multi-GPU version of SCEPTIC3D using very generalized techniques. We came away with concrete conclusions concerning the performance impacts of using a full radix sort. We also explored ways to minimize warp divergence while handling reinjections and collisions using stream compaction and recursion. Lastly, we investigated the benefits of utilizing texture memory for constant arrays that are frequently accessed. In the end, the lessons that we learned from the exploration of each of these topics enabled us implement a GPU PIC code that attained a upwards of 100 times the performance of its CPU based counterpart. 

While the end results were impressive, we learned that a PIC code implemented on the GPU can differ greatly from the same code implemented on a CPU. Over the course of this project we analyzed the methods used by others in the development of GPU PIC implementations. The main issue that was identified by most groups was how to efficiently implement the particle to mesh step on the GPU. The conclusion that we, and many of the papers we reviewed, came to was that the particle data must be sorted in order to ensure that the majority of the accumulation can be performed using fast shared memory. So far nearly every paper that we reviewed developed their own techniques to keep the particle list sorted, with each technique optimized to fit a specific problem. 
While these specialized methods can achieve higher performance, more generalized methods tend to be easier to implement, and if they can be based on external libraries, easier to maintain. 

Some of these past works produced very generalized methods. The particle-mesh integration technique developed by Stantchev et al is a good example of a broadly applicable technique. We aimed to develop more general techniques for other steps of the PIC method. We presented a fast, very general sort based on the the radix sort provided by the THRUST library. While the costs associated with this sort are not negligible, the combined costs of the sort and charge assign are still comparable to the costs of the advancing step and the field solve steps. The other general technique that we developed was a way to minimize warp divergence when dealing with reinjections and collisions. The specific algorithm presented works well when the number of collisions and reinjections are small, but can be applied more generally by changing the conditions for placing a particle in a sub-list. 

The final unique property of the GPU PIC implementation presented here is the use of texture memory as the primary data structure for the potential and the backbone of the Poisson solver. We concluded that texture memory should be used as a data structure for spatially organized data. Of course there are drawbacks to texture memory, primarily that the very strict usage properties can make it difficult to integrate with the rest of the code. 



\section{Implications}
We were able to achieve speedup factors of 160 versus older CPUs and factors of 60 versus newer Intel i7 CPUs. With these speedup factors it is possible to attain cluster level performance on a multi-GPU workstation for SCEPTIC3D. In the tests we performed, we ran 50 million particles per GTX 590. There are commercially available workstations that support up to 8 graphics cards. Populated with 8x GTX 590 graphics cards, one of these workstations would be the equivalent of a 2560 core cluster for the purposes of running SCEPTIC3D. Essentially a GPU enabled SCEPTIC3D can attain cluster level performance on a single workstation. 

While we managed to improve the performance of the particle advancing and the particle-mesh interpolation steps by factors of 122 and 104 respectively, we ran into the issue where the Poisson solve became the dominant cost. As we saw in chapter \ref{ch:performance} when the grid becomes much larger than $64^3$ the cost of the Poisson solve dominates. If we start to consider even larger grid sizes, we eventually run into the limit where we are using more memory for the grid than the particle data. At that point we would have to decompose the domain across multiple GPUs such that each GPU only moved particles on part of the grid. This would greatly complicate the entire system because particles that leave one sub-domain would have to be passed from one GPU to another. Smaller PIC codes should not have to worry too much about this, although methods will have to be developed to handle this efficiently for larger codes.

One of the biggest implications of this work is its effect on the particle sorting step. Previous groups attempted to solve the sorting question using the radix sort implementation provided by the CUDPP library. However, this implementation was unacceptably slow, and combined with the poor memory access patterns of older cards, the library sort was out of the question. Recently the radix sort, now provided by the THRUST library, has been significantly improved. This fact, combined with the improved memory access patterns has resulted in a radix based particle sort method with significantly better performance. The performance of the THRUST sort is currently good enough that there is little reason to develop a specialized sorting technique. 

\section{Future Work}
Within the scope of the GPU implementation of SCPETIC there is at least one additional physics component that has not yet been included due to time constraints, the collision operator. While we have laid out the framework for implementing collisions on the GPU we have not yet implemented the entirety of that framework. Additionally, the re-injection particle list is currently calculated on the CPU, and a portion of this 'pool' is transfered to the GPU during the re-injection phase. Refilling the particle list on the CPU currently costs about 1/3\textsuperscript{rd} the cost of the particle advance. Implementing this on the GPU would significantly reduce the cost of this step, as well as eliminate the particle list transpose and host to device memory copy currently required. Further improvements to SCEPTIC3D could be made by optimizing the advancing kernel, specifically optimizing the force interpolation function to require fewer registers. 

Pertaining to GPU PIC implementations in general, more work needs to be done concerning large grid sizes. As previously stated, two of the major issues facing larger scale GPU PIC implementations are multi-GPUs domain decomposition and optimizing large field solves. Developing asynchronous techniques that perform computations on both the GPU and CPU simultaneously is another high priority. 



